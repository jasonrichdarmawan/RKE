{
    "model_name": "Llama3-8B-Instruct",
    "layers": [
        7
    ],
    "clamp_norm_factor": 4,
    "layer_selection": "all",
    "fact_token": "last",
    "lr": 2e-4,
    "v_num_grad_steps": 25,
    "v_lr": 5e-1,
    "v_loss_layer": 31,
    "v_weight_decay": 1e-3,
    "early_stop_patience": 100,
    "ex_data_num": 20,
    "rewrite_module_tmp": [
        "model.layers.{}.self_attn.q_proj",
        "model.layers.{}.self_attn.k_proj",
        "model.layers.{}.self_attn.v_proj",
        "model.layers.{}.self_attn.o_proj",
        "model.layers.{}.mlp.gate_proj",
        "model.layers.{}.mlp.up_proj",
        "model.layers.{}.mlp.down_proj"
    ],
    "layer_module_tmp": "model.layers.{}",
    "mlp_module_tmp": "model.layers.{}.mlp",
    "attn_module_tmp": "model.layers.{}.self_attn",
    "ln_f_module": "model.norm",
    "lm_head_module": "lm_head",
    "mom2_dataset": "wikipedia",
    "mom2_n_samples": 100000,
    "mom2_dtype": "float32",
    "nullspace_threshold": 2e-2,
    "update_abs_floor": 1e-5,
    "update_abs_cap": 5e-5,
    "update_rel_frac": 5e-3,
    "L2": 0,
    "reg_warmup_steps": 30,
    "reg_abs_floor": 2e-5,
    "reg_abs_cap": 5e-5,
    "reg_rel_frac": 5e-3,
    "previous_scale": 100,
    "prev_warmup_steps": 20,
    "prev_abs_floor": 1e-6,
    "prev_abs_cap": 5e-6,
    "prev_rel_frac": 5e-3,
    "window_size": 40,
    "overlap": 0,
    "r": 64,
    "lora_alpha": 256,
    "lora_dropout": 0.05
}